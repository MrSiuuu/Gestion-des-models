"""
TP5 - Techniques Avanc√©es & MLOps
Master 1 Data Engineering - YNOV Montpellier

Nom & Pr√©nom : ___________________
Date : ___________________

Objectif : D√©velopper un syst√®me de d√©tection de fraude bancaire
"""

# =============================================================================
# IMPORTS ET CONFIGURATION
# =============================================================================

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
from time import time

# Configuration
warnings.filterwarnings('ignore')
sns.set_style('whitegrid')
plt.rcParams['figure.figsize'] = (12, 6)
RANDOM_STATE = 42
np.random.seed(RANDOM_STATE)

# Imports Scikit-Learn
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report, roc_auc_score
)

# Imports des algorithmes
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier

# Imports optimisation
from sklearn.model_selection import RandomizedSearchCV
from sklearn.decomposition import PCA
from sklearn.feature_selection import SelectKBest, f_classif

# Imports pipeline
from sklearn.pipeline import Pipeline

# Imports utilitaires locaux
from utils import (
    load_fraud_dataset,
    plot_confusion_matrix,
    plot_roc_curve,
    compare_models_performance,
    plot_feature_importance,
    detect_data_drift,
    save_model_info
)

print("‚úì Tous les imports r√©ussis")

# =============================================================================
# PARTIE 1 : EXPLORATION ET PR√âPARATION (45 min)
# =============================================================================

print("\n" + "="*80)
print("PARTIE 1 : EXPLORATION ET PR√âPARATION")
print("="*80)

# 1.1 Chargement des donn√©es
# TODO: Charger le dataset avec load_fraud_dataset()
# Pour tests rapides: sample_size=50000
df = None  # √Ä COMPL√âTER

# TODO: Afficher les premi√®res lignes


# TODO: Afficher les informations g√©n√©rales (shape, dtypes, describe, valeurs manquantes)


# 1.2 Analyse du d√©s√©quilibre
# TODO: Analyser la distribution de la classe cible
# Compter les occurrences, calculer les pourcentages et le ratio


# QUESTION 1.1: Quel est le pourcentage de transactions frauduleuses ?
# R√âPONSE:

# QUESTION 1.2: Pourquoi ce d√©s√©quilibre pose-t-il probl√®me ?
# R√âPONSE:

# 1.3 Visualisations
# TODO: Cr√©er 3-4 visualisations pertinentes
# - Distribution de la classe cible
# - Distribution des montants par classe
# - Distribution temporelle des fraudes
# - Matrice de corr√©lation (√©chantillon)


# 1.4 Pr√©paration des donn√©es
# TODO: S√©parer features (X) et cible (y)
X = None  # √Ä COMPL√âTER
y = None  # √Ä COMPL√âTER

# TODO: Split train/test stratifi√© (80/20)
X_train, X_test, y_train, y_test = None, None, None, None  # √Ä COMPL√âTER

# TODO: Normaliser UNIQUEMENT Time et Amount
# Les features V1-V28 sont d√©j√† normalis√©es !


print("\n‚úÖ CHECKPOINT PARTIE 1 : Donn√©es pr√©par√©es")

# =============================================================================
# PARTIE 2 : ALGORITHMES AVANC√âS (90 min)
# =============================================================================

print("\n" + "="*80)
print("PARTIE 2 : ALGORITHMES AVANC√âS")
print("="*80)

# Dictionnaire pour stocker les r√©sultats
results = {}

# 2.1 Support Vector Machine (SVM)
print("\n--- 2.1 SVM ---")

# TODO: Cr√©er et entra√Æner un SVM
# Param√®tres: kernel='rbf', C=1.0, class_weight='balanced', probability=True
start_time = time()
svm_model = None  # √Ä COMPL√âTER
# svm_model.fit(X_train, y_train)
svm_time = time() - start_time

# TODO: √âvaluer le SVM
y_pred_svm = None  # √Ä COMPL√âTER
y_proba_svm = None  # √Ä COMPL√âTER ([:,1] pour la classe positive)

svm_accuracy = None  # √Ä COMPL√âTER
svm_precision = None  # √Ä COMPL√âTER
svm_recall = None  # √Ä COMPL√âTER
svm_f1 = None  # √Ä COMPL√âTER
svm_auc = None  # √Ä COMPL√âTER

print(f"SVM - F1: {svm_f1:.4f}, AUC: {svm_auc:.4f}, Temps: {svm_time:.2f}s")

# TODO: Afficher la matrice de confusion
# plot_confusion_matrix(y_test, y_pred_svm, title="SVM")

# Stocker les r√©sultats
results['SVM'] = {
    'accuracy': svm_accuracy,
    'precision': svm_precision,
    'recall': svm_recall,
    'f1': svm_f1,
    'auc': svm_auc
}

# QUESTION 2.1: Quel noyau SVM performe le mieux ? (Testez linear, rbf, poly)
# R√âPONSE:

# 2.2 K-Nearest Neighbors (KNN)
print("\n--- 2.2 KNN ---")

# TODO: Tester diff√©rentes valeurs de K
k_values = [3, 5, 10, 20, 50]
knn_scores = []

for k in k_values:
    # TODO: Cr√©er, entra√Æner et √©valuer KNN
    # Param√®tres: n_neighbors=k, weights='distance'
    pass

# TODO: Identifier le meilleur K
best_k = None  # √Ä d√©terminer

# TODO: √âvaluer compl√®tement le meilleur KNN
knn_model = None  # √Ä COMPL√âTER
y_pred_knn = None
y_proba_knn = None

knn_f1 = None  # √Ä COMPL√âTER
knn_auc = None  # √Ä COMPL√âTER

print(f"KNN (k={best_k}) - F1: {knn_f1:.4f}, AUC: {knn_auc:.4f}")

# QUESTION 2.2: Pourquoi un K trop petit ou trop grand est probl√©matique ?
# R√âPONSE:

# QUESTION 2.3: KNN est-il adapt√© pour ce probl√®me ? Justifiez.
# R√âPONSE:

# 2.3 XGBoost
print("\n--- 2.3 XGBoost ---")

# TODO: Calculer scale_pos_weight
scale_pos_weight = None  # n_negative / n_positive

# TODO: Cr√©er et entra√Æner XGBoost
start_time = time()
xgb_model = None  # √Ä COMPL√âTER
# Param√®tres: n_estimators=100, max_depth=5, learning_rate=0.1,
#            scale_pos_weight=..., random_state=42
xgb_time = time() - start_time

# TODO: √âvaluer XGBoost
y_pred_xgb = None
y_proba_xgb = None

xgb_f1 = None
xgb_auc = None

print(f"XGBoost - F1: {xgb_f1:.4f}, AUC: {xgb_auc:.4f}, Temps: {xgb_time:.2f}s")

# TODO: Afficher l'importance des features (top 10)
# feature_names = X.columns.tolist()
# importances = xgb_model.feature_importances_
# plot_feature_importance(feature_names, importances, top_n=10)

# 2.4 LightGBM
print("\n--- 2.4 LightGBM ---")

# TODO: Cr√©er et entra√Æner LightGBM
start_time = time()
lgbm_model = None  # √Ä COMPL√âTER
# Param√®tres: n_estimators=100, max_depth=5, learning_rate=0.1,
#            scale_pos_weight=..., random_state=42, verbose=-1
lgbm_time = time() - start_time

# TODO: √âvaluer LightGBM
y_pred_lgbm = None
y_proba_lgbm = None

lgbm_f1 = None
lgbm_auc = None

print(f"LightGBM - F1: {lgbm_f1:.4f}, AUC: {lgbm_auc:.4f}, Temps: {lgbm_time:.2f}s")
print(f"Comparaison vitesse: XGBoost={xgb_time:.2f}s vs LightGBM={lgbm_time:.2f}s")

# 2.5 Comparaison globale
print("\n--- 2.5 Comparaison Globale ---")

# TODO: Compl√©ter le dictionnaire results avec tous les mod√®les
results['KNN'] = {'f1': knn_f1, 'auc': knn_auc}  # Compl√©ter avec toutes les m√©triques
results['XGBoost'] = {'f1': xgb_f1, 'auc': xgb_auc}  # Idem
results['LightGBM'] = {'f1': lgbm_f1, 'auc': lgbm_auc}  # Idem

# TODO: Afficher la comparaison
# compare_models_performance(results)

# QUESTION 2.4: Quel mod√®le performe le mieux ? Selon quelle m√©trique ?
# R√âPONSE:

# QUESTION 2.5: Pourquoi l'Accuracy n'est pas une bonne m√©trique ici ?
# R√âPONSE:

# QUESTION 2.6: Trade-off Precision vs Recall dans la d√©tection de fraude ?
# R√âPONSE:

print("\n‚úÖ CHECKPOINT PARTIE 2 : 4 algorithmes √©valu√©s")

# =============================================================================
# PARTIE 3 : OPTIMISATION & DIMENSIONNALIT√â (60 min)
# =============================================================================

print("\n" + "="*80)
print("PARTIE 3 : OPTIMISATION & DIMENSIONNALIT√â")
print("="*80)

# 3.1 RandomizedSearchCV sur XGBoost
print("\n--- 3.1 RandomizedSearchCV ---")

# TODO: D√©finir l'espace de recherche
param_distributions = {
    'n_estimators': [100, 200, 300, 500],
    'max_depth': [3, 5, 7, 9],
    'learning_rate': [0.01, 0.05, 0.1, 0.2],
    'subsample': [0.6, 0.8, 1.0],
    'colsample_bytree': [0.6, 0.8, 1.0],
    'min_child_weight': [1, 3, 5],
    'gamma': [0, 0.1, 0.2]
}

# TODO: Lancer RandomizedSearchCV
# Param√®tres: n_iter=50, cv=5, scoring='f1', n_jobs=-1, verbose=1
print("Lancement de RandomizedSearchCV (plusieurs minutes)...")

xgb_base = XGBClassifier(scale_pos_weight=scale_pos_weight, random_state=RANDOM_STATE)
random_search = None  # √Ä COMPL√âTER (RandomizedSearchCV)

# random_search.fit(X_train, y_train)

# TODO: Afficher les meilleurs hyperparam√®tres
# print("Meilleurs hyperparam√®tres:", random_search.best_params_)
# print(f"Meilleur score CV: {random_search.best_score_:.4f}")

# TODO: √âvaluer le mod√®le optimis√©
# xgb_optimized = random_search.best_estimator_
# y_pred_opt = xgb_optimized.predict(X_test)
# xgb_opt_f1 = f1_score(y_test, y_pred_opt)
# print(f"F1-Score optimis√©: {xgb_opt_f1:.4f}")

# QUESTION 3.1: Pourquoi RandomizedSearchCV plut√¥t que GridSearchCV ?
# R√âPONSE:

# 3.2 R√©duction de Dimension avec PCA
print("\n--- 3.2 PCA ---")

# TODO: Appliquer PCA pour conserver 95% de variance
pca = None  # √Ä COMPL√âTER (PCA avec n_components=0.95)

# X_train_pca = pca.fit_transform(X_train)
# X_test_pca = pca.transform(X_test)

# print(f"Dimensions originales: {X_train.shape[1]}")
# print(f"Dimensions apr√®s PCA: {X_train_pca.shape[1]}")
# print(f"Variance expliqu√©e: {pca.explained_variance_ratio_.sum():.4f}")

# TODO: Entra√Æner XGBoost sur donn√©es PCA et comparer


# QUESTION 3.2: Dans quel contexte PCA est recommand√© avant KNN ?
# R√âPONSE:

# 3.3 Feature Selection
print("\n--- 3.3 Feature Selection ---")

# TODO: S√©lectionner les K=15 meilleures features
selector = None  # √Ä COMPL√âTER (SelectKBest, k=15)

# X_train_selected = selector.fit_transform(X_train, y_train)
# X_test_selected = selector.transform(X_test)

# TODO: Identifier et afficher les features s√©lectionn√©es


# TODO: Entra√Æner un mod√®le sur les features s√©lectionn√©es et comparer


print("\n‚úÖ CHECKPOINT PARTIE 3 : Optimisation effectu√©e")

# =============================================================================
# PARTIE 4 : INTRODUCTION MLOPS (45 min)
# =============================================================================

print("\n" + "="*80)
print("PARTIE 4 : INTRODUCTION MLOPS")
print("="*80)

# 4.1 MLflow Tracking
print("\n--- 4.1 MLflow Tracking ---")

import mlflow
import mlflow.sklearn

# TODO: Configurer MLflow
mlflow.set_experiment("fraud_detection_tp5")

# TODO: Tracker une exp√©rimentation
# with mlflow.start_run(run_name="xgboost_baseline"):
#     mlflow.log_param("n_estimators", 100)
#     mlflow.log_param("max_depth", 5)
#     mlflow.log_metric("f1_score", xgb_f1)
#     mlflow.log_metric("roc_auc", xgb_auc)
#     mlflow.sklearn.log_model(xgb_model, "model")

print("‚úì Pour voir l'UI MLflow: mlflow ui (puis http://localhost:5000)")

# 4.2 Pipeline de Production
print("\n--- 4.2 Pipeline de Production ---")

# TODO: Cr√©er un pipeline complet Preprocessing + Model


# TODO: Sauvegarder le pipeline
import joblib
# joblib.dump(pipeline, 'fraud_detection_pipeline.pkl')

# 4.3 Monitoring - Data Drift
print("\n--- 4.3 Data Drift ---")

# TODO: Simuler un drift en modifiant certaines features
# X_production = X_test.copy()
# X_production['Amount'] = X_production['Amount'] * 1.5

# TODO: D√©tecter et visualiser le drift
# detect_data_drift(X_train, X_production, feature='Amount')

# QUESTION 4.1: Comment d√©tecter automatiquement un drift en production ?
# R√âPONSE:

# 4.4 Versioning et Reproductibilit√©
print("\n--- 4.4 Versioning ---")

# TODO: Sauvegarder les m√©tadonn√©es du mod√®le
# metadata = {
#     'f1_score': xgb_f1,
#     'roc_auc': xgb_auc,
#     'training_samples': len(X_train)
# }
# save_model_info(xgb_model, 'model_info.json', metadata=metadata)

print("\n‚úÖ CHECKPOINT PARTIE 4 : MLOps appliqu√©")

# =============================================================================
# SYNTH√àSE FINALE
# =============================================================================

print("\n" + "="*80)
print("SYNTH√àSE FINALE")
print("="*80)

print("""
R√©sum√© de vos r√©sultats :

Meilleur mod√®le : _________________

Performances :
- F1-Score : _______
- ROC-AUC : _______
- Precision : _______
- Recall : _______

Optimisations appliqu√©es :
[ ] RandomizedSearchCV
[ ] PCA
[ ] Feature Selection
[ ] Gestion d√©s√©quilibre

MLOps :
[ ] MLflow tracking
[ ] Pipeline production
[ ] Monitoring drift
[ ] Versioning mod√®le

Difficult√©s rencontr√©es :
1. 
2. 
3. 

Pistes d'am√©lioration :
1. 
2. 
3. 
""")

print("\nüéâ F√©licitations ! TP5 termin√© !")
print("N'oubliez pas de sauvegarder vos r√©sultats et soumettre les livrables.")
