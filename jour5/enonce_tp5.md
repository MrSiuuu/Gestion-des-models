# TP5 - Techniques Avanc√©es & MLOps

**Master 1 Data Engineering - YNOV Montpellier**  
**Cours 5 : Techniques Avanc√©es & MLOps**  
**Dur√©e : 4 heures**  
**Enseignant : BENHAMDI Ayoub**

---

## üìã Contexte & Objectifs

### Contexte M√©tier

Vous travaillez pour un op√©rateur de t√©l√©communications qui souhaite prot√©ger ses clients contre les SMS ind√©sirables (spam). Votre mission est de d√©velopper un syst√®me de d√©tection automatique de spam SMS bas√© sur l'analyse du contenu textuel des messages.

Le d√©fi principal : **environ 13.4% des messages sont du spam**, ce qui repr√©sente un probl√®me de classes d√©s√©quilibr√©es n√©cessitant des techniques avanc√©es de Machine Learning et de traitement du langage naturel (NLP).

### Objectifs P√©dagogiques

√Ä l'issue de ce TP, vous serez capable de :

1. ‚úÖ **Traiter des donn√©es textuelles** avec vectorisation TF-IDF
2. ‚úÖ **Ma√Ætriser les algorithmes avanc√©s** : SVM, KNN, XGBoost et LightGBM
3. ‚úÖ **Optimiser les hyperparam√®tres** avec RandomizedSearchCV
4. ‚úÖ **R√©duire la dimensionnalit√©** avec TruncatedSVD et feature selection
5. ‚úÖ **Appliquer les concepts MLOps** : versioning, tracking et monitoring
6. ‚úÖ **G√©rer le d√©s√©quilibre de classes** avec des techniques appropri√©es

---

## üéØ Comp√©tences Vis√©es

- **NLP (Natural Language Processing)** : Vectorisation TF-IDF, analyse de texte
- **Algorithmique ML** : Impl√©menter et comparer des algorithmes sophistiqu√©s
- **Optimisation** : Trouver les meilleurs hyperparam√®tres efficacement
- **√âvaluation** : Utiliser des m√©triques adapt√©es (F1-Score, ROC-AUC, Precision-Recall)
- **MLOps** : Tracker les exp√©rimentations avec MLflow
- **Production** : Cr√©er des pipelines robustes et reproductibles

---

## üì¶ Pr√©requis

### Installation

```bash
# Installer les d√©pendances
pip install -r requirements.txt

# T√©l√©charger le dataset Kaggle (voir data/README.md)
kaggle datasets download -d uciml/sms-spam-collection-dataset
```

### Dataset

- **Source** : Kaggle - SMS Spam Collection Dataset
- **Lien** : https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset
- **Taille** : ~500 KB (5,574 messages SMS)
- **Spam** : ~747 (13.4%)
- **Ham (l√©gitime)** : ~4,827 (86.6%)
- **Langue** : Anglais

‚ö†Ô∏è **Important** : T√©l√©chargez le dataset **AVANT** le d√©but du TP (voir `data/README.md` pour les instructions d√©taill√©es).

### Fichiers fournis

- `utils.py` : Fonctions utilitaires pour les visualisations
- `tp5_template.py` : Script Python √† compl√©ter
- `data/README.md` : Instructions pour t√©l√©charger le dataset

---

## üèóÔ∏è Structure du TP

Le TP est divis√© en **4 parties progressives** :

### **Partie 1** : Exploration et Pr√©paration (45 min) - `/20`
- Chargement et analyse exploratoire
- Analyse des caract√©ristiques textuelles
- Vectorisation TF-IDF
- Split train/test stratifi√©

### **Partie 2** : Algorithmes Avanc√©s (90 min) - `/30`
- Support Vector Machines (SVM)
- K-Nearest Neighbors (KNN)
- XGBoost et LightGBM
- Comparaison des performances

### **Partie 3** : Optimisation & Dimensionnalit√© (60 min) - `/30`
- RandomizedSearchCV
- R√©duction de dimension avec TruncatedSVD
- Feature selection
- Learning curves

### **Partie 4** : Introduction MLOps (45 min) - `/20`
- MLflow tracking
- Pipelines de production
- Monitoring et data drift
- Sauvegarde et versioning

---

## üìù Partie 1 : Exploration et Pr√©paration (45 min)

### Objectifs

- Comprendre la structure et les caract√©ristiques du dataset
- Analyser les messages spam vs ham
- Vectoriser le texte avec TF-IDF
- Pr√©parer les donn√©es pour la mod√©lisation

### T√¢ches √† r√©aliser

#### 1.1 Chargement des donn√©es

```python
# Utiliser la fonction fournie dans utils.py
from utils import load_spam_dataset

df = load_spam_dataset('data/spam.csv')
```

#### 1.2 Analyse Exploratoire des Donn√©es (EDA)

- Afficher les dimensions, types de donn√©es et statistiques descriptives
- V√©rifier les valeurs manquantes
- Analyser la r√©partition de la variable cible `label` (spam/ham)
- Calculer le ratio de d√©s√©quilibre
- **Analyser la longueur des messages** :
  - Nombre de caract√®res par message
  - Nombre de mots par message
  - Comparer spam vs ham

**Questions de r√©flexion** :
- Quel est le pourcentage de spam ?
- Pourquoi ce d√©s√©quilibre pose-t-il probl√®me pour les algorithmes ML classiques ?
- Les messages spam sont-ils g√©n√©ralement plus longs ou plus courts que les messages l√©gitimes ?

#### 1.3 Visualisations

Cr√©er les visualisations suivantes :

1. **Distribution de la variable cible** (bar plot spam vs ham)
2. **Distribution de la longueur des messages** :
   - Histogramme du nombre de caract√®res (spam vs ham)
   - Histogramme du nombre de mots (spam vs ham)
3. **Top 15-20 mots les plus fr√©quents** :
   - Dans les messages spam
   - Dans les messages ham
   - Comparer les diff√©rences
4. **(Optionnel)** Nuage de mots (WordCloud) pour spam et ham

üí° **Astuce** : Utilisez `seaborn` et `matplotlib` pour des graphiques professionnels.

**Code exemple pour analyser les mots fr√©quents** :

```python
from collections import Counter
import re

def get_word_frequency(messages, top_n=20):
    # Concat√©ner tous les messages
    text = ' '.join(messages)
    # Extraire les mots (minuscules, sans ponctuation)
    words = re.findall(r'\b\w+\b', text.lower())
    # Compter les occurrences
    word_counts = Counter(words)
    return word_counts.most_common(top_n)

# Exemple d'utilisation
spam_messages = df[df['label'] == 'spam']['message']
top_spam_words = get_word_frequency(spam_messages, top_n=20)
```

#### 1.4 Pr√©paration des donn√©es

**√âtape 1 : Encoder la cible**

```python
# Convertir 'spam' ‚Üí 1 et 'ham' ‚Üí 0
from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
y = le.fit_transform(df['label'])  # spam=1, ham=0
```

**√âtape 2 : Vectorisation TF-IDF**

Le texte brut ne peut pas √™tre utilis√© directement par les algorithmes ML. Il faut le convertir en vecteurs num√©riques avec **TF-IDF** (Term Frequency-Inverse Document Frequency).

```python
from sklearn.feature_extraction.text import TfidfVectorizer

# Cr√©er le vectoriseur
vectorizer = TfidfVectorizer(
    max_features=3000,        # Garder les 3000 mots les plus importants
    stop_words='english',      # Supprimer les mots courants (the, is, at...)
    lowercase=True,            # Tout en minuscules
    ngram_range=(1, 2)        # Utiliser uni-grams et bi-grams
)

# Vectoriser les messages
X = vectorizer.fit_transform(df['message'])

print(f"Shape de X: {X.shape}")  # (5574, 3000)
print(f"Type de X: {type(X)}")   # sparse matrix (efficace en m√©moire)
```

üí° **Explications** :
- **TF-IDF** : Mesure l'importance d'un mot dans un document par rapport √† tous les documents
- **max_features** : Limite le vocabulaire (sinon trop de features)
- **stop_words** : Mots courants sans valeur s√©mantique
- **ngram_range=(1,2)** : Capture les mots seuls (uni-grams) et les paires de mots (bi-grams)

**√âtape 3 : Split train/test stratifi√©**

```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    stratify=y,           # CRUCIAL : pr√©server les proportions
    random_state=42
)

print(f"Train set: {X_train.shape}")
print(f"Test set: {X_test.shape}")
print(f"\nDistribution train: {pd.Series(y_train).value_counts()}")
print(f"Distribution test: {pd.Series(y_test).value_counts()}")
```

‚ö†Ô∏è **ATTENTION** : 
- **NE PAS** faire `fit_transform()` sur le test set ‚Üí DATA LEAKAGE !
- Toujours `fit()` sur train, puis `transform()` sur test
- Avec le pipeline (Partie 4), cela sera automatique

**Livrable Partie 1** :
- ‚úÖ Dataset charg√© et analys√©
- ‚úÖ Au moins 3 visualisations pertinentes
- ‚úÖ Texte vectoris√© avec TF-IDF (3000 features)
- ‚úÖ Donn√©es pr√©par√©es (X_train, X_test, y_train, y_test)

---

## ü§ñ Partie 2 : Algorithmes Avanc√©s (90 min)

### Objectifs

- Impl√©menter et comparer 4 algorithmes sophistiqu√©s
- Comprendre l'impact des hyperparam√®tres
- √âvaluer avec des m√©triques adapt√©es au d√©s√©quilibre

### 2.1 Support Vector Machine (SVM)

#### Impl√©mentation

```python
from sklearn.svm import SVC
from time import time

# TODO: Cr√©er et entra√Æner un SVM
svm_model = SVC(
    kernel='rbf',              # Noyau RBF (Gaussian)
    C=1.0,                     # R√©gularisation
    class_weight='balanced',   # CRUCIAL pour le d√©s√©quilibre
    probability=True,          # Pour predict_proba (ROC-AUC)
    random_state=42
)

start_time = time()
svm_model.fit(X_train, y_train)
svm_time = time() - start_time

print(f"‚úì SVM entra√Æn√© en {svm_time:.2f}s")
```

#### √âvaluation

```python
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

# Pr√©dictions
y_pred_svm = svm_model.predict(X_test)
y_proba_svm = svm_model.predict_proba(X_test)[:, 1]  # Probabilit√©s classe positive

# M√©triques
svm_accuracy = accuracy_score(y_test, y_pred_svm)
svm_precision = precision_score(y_test, y_pred_svm)
svm_recall = recall_score(y_test, y_pred_svm)
svm_f1 = f1_score(y_test, y_pred_svm)
svm_auc = roc_auc_score(y_test, y_proba_svm)

print(f"Accuracy: {svm_accuracy:.4f}")
print(f"Precision: {svm_precision:.4f}")
print(f"Recall: {svm_recall:.4f}")
print(f"F1-Score: {svm_f1:.4f}")
print(f"ROC-AUC: {svm_auc:.4f}")
```

#### Visualisations

```python
from utils import plot_confusion_matrix, plot_roc_curve

# Matrice de confusion
plot_confusion_matrix(y_test, y_pred_svm, title="SVM RBF - Matrice de Confusion")

# Courbe ROC
plot_roc_curve(y_test, y_proba_svm, model_name="SVM RBF")
```

#### Exp√©rimentation : Tester diff√©rents noyaux

Testez **3 configurations** :

1. **SVM Linear** : `kernel='linear'`, `C=1.0`
2. **SVM RBF** : `kernel='rbf'`, `C=1.0` (d√©j√† fait)
3. **SVM Polynomial** : `kernel='poly'`, `degree=3`, `C=1.0`

Pour chaque configuration, calculez et comparez les m√©triques.

üí° **Note** : Le noyau **linear** est souvent tr√®s performant pour les donn√©es textuelles en haute dimension (TF-IDF cr√©e ~3000 features).

**Question 2.1** : Quel noyau performe le mieux pour la classification de texte ? Pourquoi ?

_R√©ponse attendue_ : Linear est g√©n√©ralement excellent pour le texte car les donn√©es TF-IDF sont d√©j√† en haute dimension et souvent lin√©airement s√©parables.

---

### 2.2 K-Nearest Neighbors (KNN)

#### Impl√©mentation

```python
from sklearn.neighbors import KNeighborsClassifier

# TODO: Tester diff√©rentes valeurs de K
k_values = [3, 5, 10, 20, 50]
knn_scores = []

print("Test de diff√©rentes valeurs de K:")
for k in k_values:
    knn = KNeighborsClassifier(n_neighbors=k, weights='distance')
    knn.fit(X_train, y_train)
    y_pred = knn.predict(X_test)
    f1 = f1_score(y_test, y_pred)
    knn_scores.append(f1)
    print(f"  K={k}: F1={f1:.4f}")
```

#### Visualisation

```python
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
plt.plot(k_values, knn_scores, marker='o', linewidth=2, markersize=8)
plt.xlabel('Nombre de voisins (K)', fontsize=12)
plt.ylabel('F1-Score', fontsize=12)
plt.title('Performance KNN en fonction de K', fontsize=14, fontweight='bold')
plt.grid(alpha=0.3)
plt.show()
```

#### √âvaluation du meilleur K

```python
# TODO: Identifier le meilleur K
best_k_idx = np.argmax(knn_scores)
best_k = k_values[best_k_idx]

print(f"\nMeilleur K: {best_k}")

# Entra√Æner et √©valuer compl√®tement
knn_model = KNeighborsClassifier(n_neighbors=best_k, weights='distance')
knn_model.fit(X_train, y_train)

y_pred_knn = knn_model.predict(X_test)
y_proba_knn = knn_model.predict_proba(X_test)[:, 1]

knn_f1 = f1_score(y_test, y_pred_knn)
knn_auc = roc_auc_score(y_test, y_proba_knn)

print(f"F1-Score: {knn_f1:.4f}")
print(f"ROC-AUC: {knn_auc:.4f}")
```

**Question 2.2** : Pourquoi un K trop petit ou trop grand est probl√©matique ?

_R√©ponse_ : K trop petit = overfitting (sensible au bruit), K trop grand = underfitting (fronti√®re trop lisse).

**Question 2.3** : KNN est-il adapt√© pour la classification de texte en haute dimension ? Justifiez.

_R√©ponse_ : KNN n'est pas id√©al car :
- Tr√®s lent en pr√©diction (calcul de distances pour tous les points)
- "Curse of dimensionality" avec 3000 features
- Distances moins significatives en haute dimension

---

### 2.3 XGBoost

#### Calcul du scale_pos_weight

```python
# Pour g√©rer le d√©s√©quilibre de classes
scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()
print(f"scale_pos_weight: {scale_pos_weight:.2f}")
```

#### Impl√©mentation

```python
from xgboost import XGBClassifier

xgb_model = XGBClassifier(
    n_estimators=100,
    max_depth=5,
    learning_rate=0.1,
    scale_pos_weight=scale_pos_weight,  # CRUCIAL
    random_state=42,
    eval_metric='logloss'
)

start_time = time()
xgb_model.fit(X_train, y_train)
xgb_time = time() - start_time

print(f"‚úì XGBoost entra√Æn√© en {xgb_time:.2f}s")
```

#### √âvaluation

```python
y_pred_xgb = xgb_model.predict(X_test)
y_proba_xgb = xgb_model.predict_proba(X_test)[:, 1]

xgb_f1 = f1_score(y_test, y_pred_xgb)
xgb_auc = roc_auc_score(y_test, y_proba_xgb)

print(f"F1-Score: {xgb_f1:.4f}")
print(f"ROC-AUC: {xgb_auc:.4f}")
```

#### Analyse des features importantes

```python
# R√©cup√©rer les noms des mots (features)
feature_names = vectorizer.get_feature_names_out()
importances = xgb_model.feature_importances_

# Top 20 mots les plus importants
top_indices = np.argsort(importances)[::-1][:20]

print("\nTop 20 mots les plus importants pour d√©tecter le spam:")
for i, idx in enumerate(top_indices, 1):
    print(f"  {i}. {feature_names[idx]}: {importances[idx]:.4f}")
```

üí° **Interpr√©tation** : Ces mots sont ceux qui permettent le mieux de distinguer spam vs ham. V√©rifiez qu'ils ont du sens (ex: "free", "win", "prize", "call" pour spam).

---

### 2.4 LightGBM

```python
from lightgbm import LGBMClassifier

lgbm_model = LGBMClassifier(
    n_estimators=100,
    max_depth=5,
    learning_rate=0.1,
    scale_pos_weight=scale_pos_weight,
    random_state=42,
    verbose=-1
)

start_time = time()
lgbm_model.fit(X_train, y_train)
lgbm_time = time() - start_time

y_pred_lgbm = lgbm_model.predict(X_test)
y_proba_lgbm = lgbm_model.predict_proba(X_test)[:, 1]

lgbm_f1 = f1_score(y_test, y_pred_lgbm)
lgbm_auc = roc_auc_score(y_test, y_proba_lgbm)

print(f"‚úì LightGBM entra√Æn√© en {lgbm_time:.2f}s")
print(f"F1-Score: {lgbm_f1:.4f}")
print(f"ROC-AUC: {lgbm_auc:.4f}")
print(f"\nComparaison vitesse: XGBoost={xgb_time:.2f}s vs LightGBM={lgbm_time:.2f}s")
```

---

### 2.5 Comparaison Globale

```python
# Cr√©er un dictionnaire avec tous les r√©sultats
results = {
    'SVM': {
        'accuracy': svm_accuracy,
        'precision': svm_precision,
        'recall': svm_recall,
        'f1': svm_f1,
        'auc': svm_auc
    },
    'KNN': {
        'f1': knn_f1,
        'auc': knn_auc
        # TODO: Ajouter les autres m√©triques
    },
    'XGBoost': {
        'f1': xgb_f1,
        'auc': xgb_auc
        # TODO: Compl√©ter
    },
    'LightGBM': {
        'f1': lgbm_f1,
        'auc': lgbm_auc
        # TODO: Compl√©ter
    }
}

# Afficher la comparaison
from utils import compare_models_performance
compare_models_performance(results)
```

**Questions de synth√®se** :

**Q2.4** : Quel mod√®le performe le mieux sur ce probl√®me de d√©tection de spam ? Selon quelle m√©trique ?

_R√©ponse_ : [√Ä compl√©ter apr√®s exp√©rimentation]

**Q2.5** : Pourquoi l'Accuracy n'est-elle PAS une bonne m√©trique ici ?

_R√©ponse_ : Avec 86.6% de ham, un mod√®le stupide pr√©disant toujours "ham" aurait 86.6% d'accuracy mais ne d√©tecterait aucun spam. F1-Score et ROC-AUC sont plus informatifs.

**Q2.6** : Quel est le trade-off entre Precision et Recall dans le contexte de d√©tection de spam ?

_R√©ponse_ :
- **Haute Precision** : Peu de faux positifs (messages l√©gitimes marqu√©s spam) ‚Üí Meilleure exp√©rience utilisateur
- **Haut Recall** : Attraper tous les spam ‚Üí Meilleure protection mais risque de bloquer des messages l√©gitimes
- **Trade-off** : D√©pend de la priorit√© m√©tier (protection vs exp√©rience)

**Livrable Partie 2** :
- ‚úÖ 4 algorithmes impl√©ment√©s et √©valu√©s
- ‚úÖ Tableau comparatif complet
- ‚úÖ Analyse des mots importants pour la d√©tection
- ‚úÖ R√©ponses aux questions de r√©flexion

---

## ‚öôÔ∏è Partie 3 : Optimisation & Dimensionnalit√© (60 min)

### Objectifs

- Optimiser les hyperparam√®tres efficacement
- R√©duire la dimensionnalit√© avec TruncatedSVD
- S√©lectionner les features les plus pertinentes

### 3.1 RandomizedSearchCV sur XGBoost

#### D√©finir l'espace de recherche

```python
from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold

param_distributions = {
    'n_estimators': [100, 200, 300, 500],
    'max_depth': [3, 5, 7, 9],
    'learning_rate': [0.01, 0.05, 0.1, 0.2],
    'subsample': [0.6, 0.8, 1.0],
    'colsample_bytree': [0.6, 0.8, 1.0],
    'min_child_weight': [1, 3, 5],
    'gamma': [0, 0.1, 0.2]
}

print(f"Nombre d'hyperparam√®tres: {len(param_distributions)}")
print(f"Combinaisons possibles: {4*4*4*3*3*3*3:,}")
```

#### Lancer RandomizedSearchCV

```python
print("Lancement de RandomizedSearchCV (plusieurs minutes)...")

xgb_base = XGBClassifier(
    scale_pos_weight=scale_pos_weight,
    random_state=42,
    eval_metric='logloss'
)

random_search = RandomizedSearchCV(
    estimator=xgb_base,
    param_distributions=param_distributions,
    n_iter=50,                              # 50 combinaisons test√©es
    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),
    scoring='f1',                           # M√©trique √† optimiser
    n_jobs=-1,                              # Parall√©lisation
    verbose=1,
    random_state=42
)

start_time = time()
random_search.fit(X_train, y_train)
optim_time = time() - start_time

print(f"\n‚úì Optimisation termin√©e en {optim_time:.2f}s ({optim_time/60:.2f} min)")
```

#### Analyser les r√©sultats

```python
print("\nMeilleurs hyperparam√®tres:")
for param, value in random_search.best_params_.items():
    print(f"  - {param}: {value}")

print(f"\nMeilleur score CV (F1): {random_search.best_score_:.4f}")
print(f"Score de base: {xgb_f1:.4f}")
print(f"Am√©lioration: {(random_search.best_score_ - xgb_f1)*100:+.2f}%")
```

#### √âvaluer sur le test set

```python
xgb_optimized = random_search.best_estimator_

y_pred_xgb_opt = xgb_optimized.predict(X_test)
y_proba_xgb_opt = xgb_optimized.predict_proba(X_test)[:, 1]

xgb_opt_f1 = f1_score(y_test, y_pred_xgb_opt)
xgb_opt_auc = roc_auc_score(y_test, y_proba_xgb_opt)

print(f"\nPerformances sur test set:")
print(f"F1-Score optimis√©: {xgb_opt_f1:.4f} (baseline: {xgb_f1:.4f})")
print(f"ROC-AUC optimis√©: {xgb_opt_auc:.4f} (baseline: {xgb_auc:.4f})")

plot_confusion_matrix(y_test, y_pred_xgb_opt, title="XGBoost Optimis√©")
```

**Question 3.1** : Pourquoi utiliser RandomizedSearchCV plut√¥t que GridSearchCV ?

_R√©ponse_ : RandomizedSearchCV teste N combinaisons al√©atoires (50 ici) au lieu de TOUTES (6,912 ici). C'est beaucoup plus rapide avec des performances souvent similaires.

---

### 3.2 R√©duction de Dimension avec TruncatedSVD

üí° **Pourquoi TruncatedSVD et pas PCA ?** 

TF-IDF produit des **matrices creuses** (beaucoup de z√©ros). `TruncatedSVD` est optimis√© pour ce type de donn√©es, contrairement √† `PCA` qui n√©cessite des matrices denses.

#### Application

```python
from sklearn.decomposition import TruncatedSVD

# R√©duire √† 100 composantes
svd = TruncatedSVD(n_components=100, random_state=42)

X_train_svd = svd.fit_transform(X_train)
X_test_svd = svd.transform(X_test)

variance_explained = svd.explained_variance_ratio_.sum()

print(f"Dimensions originales: {X_train.shape[1]}")
print(f"Dimensions apr√®s SVD: {X_train_svd.shape[1]}")
print(f"Variance expliqu√©e: {variance_explained:.4f} ({variance_explained*100:.2f}%)")
```

#### Visualisation

```python
cumsum_variance = np.cumsum(svd.explained_variance_ratio_)

plt.figure(figsize=(12, 6))
plt.plot(range(1, len(cumsum_variance)+1), cumsum_variance, marker='o', linewidth=2)
plt.xlabel('Nombre de composantes', fontsize=12)
plt.ylabel('Variance expliqu√©e cumul√©e', fontsize=12)
plt.title('Variance Expliqu√©e par TruncatedSVD', fontsize=14, fontweight='bold')
plt.grid(alpha=0.3)
plt.show()
```

#### Mod√©lisation avec SVD

```python
print("Entra√Ænement XGBoost avec TruncatedSVD...")
start_time = time()

xgb_svd = XGBClassifier(
    n_estimators=100,
    max_depth=5,
    learning_rate=0.1,
    scale_pos_weight=scale_pos_weight,
    random_state=42,
    eval_metric='logloss'
)

xgb_svd.fit(X_train_svd, y_train)
svd_time = time() - start_time

y_pred_svd = xgb_svd.predict(X_test_svd)
svd_f1 = f1_score(y_test, y_pred_svd)

print(f"\nComparaison Sans SVD vs Avec SVD:")
print(f"Sans SVD: F1={xgb_f1:.4f}, Temps={xgb_time:.2f}s, Features={X_train.shape[1]}")
print(f"Avec SVD: F1={svd_f1:.4f}, Temps={svd_time:.2f}s, Features={X_train_svd.shape[1]}")
```

**Question 3.2** : Dans quel contexte la r√©duction de dimensionnalit√© est-elle recommand√©e avant KNN ?

_R√©ponse_ : KNN souffre du "curse of dimensionality". R√©duire les dimensions avec SVD/PCA am√©liore les performances et la vitesse.

---

### 3.3 Feature Selection

```python
from sklearn.feature_selection import SelectKBest, chi2

# S√©lectionner les K=500 meilleures features
selector = SelectKBest(score_func=chi2, k=500)

X_train_selected = selector.fit_transform(X_train, y_train)
X_test_selected = selector.transform(X_test)

# Identifier les features s√©lectionn√©es
selected_mask = selector.get_support()
selected_features = [feature_names[i] for i, selected in enumerate(selected_mask) if selected]

print(f"\nFeature Selection:")
print(f"Features originales: {X_train.shape[1]}")
print(f"Features s√©lectionn√©es: {X_train_selected.shape[1]}")
print(f"\nExemples de mots s√©lectionn√©s: {selected_features[:20]}")
```

#### Mod√©lisation

```python
xgb_fs = XGBClassifier(
    n_estimators=100,
    max_depth=5,
    learning_rate=0.1,
    scale_pos_weight=scale_pos_weight,
    random_state=42,
    eval_metric='logloss'
)

xgb_fs.fit(X_train_selected, y_train)
y_pred_fs = xgb_fs.predict(X_test_selected)
fs_f1 = f1_score(y_test, y_pred_fs)

print(f"\nComparaison:")
print(f"Toutes features: F1={xgb_f1:.4f}")
print(f"500 features: F1={fs_f1:.4f}")
```

---

### 3.4 Learning Curves (Optionnel)

```python
from sklearn.model_selection import learning_curve

print("Calcul des learning curves...")

train_sizes, train_scores, val_scores = learning_curve(
    xgb_optimized,
    X_train, y_train,
    train_sizes=np.linspace(0.1, 1.0, 10),
    cv=5,
    scoring='f1',
    n_jobs=-1
)

# Visualisation
train_mean = np.mean(train_scores, axis=1)
val_mean = np.mean(val_scores, axis=1)

plt.figure(figsize=(12, 6))
plt.plot(train_sizes, train_mean, label='Score Train', marker='o')
plt.plot(train_sizes, val_mean, label='Score Validation', marker='s')
plt.xlabel("Taille du set d'entra√Ænement", fontsize=12)
plt.ylabel('F1-Score', fontsize=12)
plt.title('Learning Curves - XGBoost Optimis√©', fontsize=14, fontweight='bold')
plt.legend()
plt.grid(alpha=0.3)
plt.show()
```

**Livrable Partie 3** :
- ‚úÖ Hyperparam√®tres optimaux trouv√©s
- ‚úÖ TruncatedSVD appliqu√©e et analys√©e
- ‚úÖ Feature selection effectu√©e
- ‚úÖ Comparaisons des performances

---

## üöÄ Partie 4 : Introduction MLOps (45 min)

### Objectifs

- Tracker les exp√©rimentations avec MLflow
- Cr√©er un pipeline de production
- Simuler un monitoring de data drift
- Assurer la reproductibilit√©

### 4.1 MLflow Tracking

#### Configuration

```python
import mlflow
import mlflow.sklearn

mlflow.set_experiment("spam_detection_tp5")

print("‚úì MLflow configur√©")
print("Pour voir l'UI MLflow: mlflow ui (puis http://localhost:5000)")
```

#### Tracker le mod√®le baseline

```python
with mlflow.start_run(run_name="xgboost_baseline"):
    # Logger hyperparam√®tres
    mlflow.log_param("n_estimators", 100)
    mlflow.log_param("max_depth", 5)
    mlflow.log_param("learning_rate", 0.1)
    mlflow.log_param("scale_pos_weight", scale_pos_weight)
    
    # Logger m√©triques
    mlflow.log_metric("f1_score", xgb_f1)
    mlflow.log_metric("roc_auc", xgb_auc)
    
    # Logger le mod√®le
    mlflow.sklearn.log_model(xgb_model, "model")
    
    print("‚úì Run 'xgboost_baseline' logged")
```

#### Tracker le mod√®le optimis√©

```python
with mlflow.start_run(run_name="xgboost_optimized"):
    # Logger tous les best_params
    for param, value in random_search.best_params_.items():
        mlflow.log_param(param, value)
    
    mlflow.log_param("scale_pos_weight", scale_pos_weight)
    mlflow.log_param("optimization_method", "RandomizedSearchCV")
    
    # Logger m√©triques
    mlflow.log_metric("f1_score", xgb_opt_f1)
    mlflow.log_metric("roc_auc", xgb_opt_auc)
    mlflow.log_metric("f1_improvement", xgb_opt_f1 - xgb_f1)
    
    # Logger le mod√®le
    mlflow.sklearn.log_model(xgb_optimized, "model")
    
    print("‚úì Run 'xgboost_optimized' logged")
```

---

### 4.2 Pipeline de Production

```python
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer

# Cr√©er un pipeline complet : Texte ‚Üí TF-IDF ‚Üí Mod√®le
production_pipeline = Pipeline([
    ('vectorizer', TfidfVectorizer(
        max_features=3000,
        stop_words='english',
        lowercase=True,
        ngram_range=(1, 2)
    )),
    ('model', xgb_optimized)
])

print("‚úì Pipeline cr√©√©")
print(production_pipeline)
```

#### Entra√Æner sur donn√©es brutes

```python
# R√©cup√©rer les messages bruts (pas encore vectoris√©s)
messages = df['message'].values
labels = le.transform(df['label'])

# Split
messages_train, messages_test, y_train_raw, y_test_raw = train_test_split(
    messages, labels, test_size=0.2, stratify=labels, random_state=42
)

# Entra√Æner le pipeline
print("Entra√Ænement du pipeline sur donn√©es brutes...")
production_pipeline.fit(messages_train, y_train_raw)

# Tester
y_pred_pipeline = production_pipeline.predict(messages_test)
pipeline_f1 = f1_score(y_test_raw, y_pred_pipeline)

print(f"‚úì Pipeline entra√Æn√© - F1-Score: {pipeline_f1:.4f}")
```

üí° **Avantage** : Le pipeline peut prendre du texte brut en entr√©e !

```python
# Test avec de nouveaux messages
new_messages = [
    "Congratulations! You've won a FREE prize! Call now!",
    "Hey, are we still meeting for lunch tomorrow?"
]

predictions = production_pipeline.predict(new_messages)
for msg, pred in zip(new_messages, predictions):
    label = "SPAM" if pred == 1 else "HAM"
    print(f"\n[{label}] {msg}")
```

#### Sauvegarder

```python
import joblib

joblib.dump(production_pipeline, 'spam_detector_pipeline.pkl')
print("‚úì Pipeline sauvegard√©: spam_detector_pipeline.pkl")

# Test de rechargement
loaded_pipeline = joblib.load('spam_detector_pipeline.pkl')
print("‚úì Pipeline recharg√© avec succ√®s")
```

---

### 4.3 Monitoring - Data Drift

#### Analyser les distributions

```python
# Analyser la longueur des messages
df['message_length'] = df['message'].str.len()

train_df = df.iloc[:len(messages_train)].copy()
test_df = df.iloc[len(messages_train):].copy()

# Comparer les longueurs
print("Longueur moyenne des messages:")
print(f"Train: {train_df['message_length'].mean():.2f}")
print(f"Test: {test_df['message_length'].mean():.2f}")

# Visualiser
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.hist(train_df['message_length'], bins=30, alpha=0.6, label='Train', density=True)
plt.hist(test_df['message_length'], bins=30, alpha=0.6, label='Test', density=True)
plt.xlabel('Longueur du message', fontsize=12)
plt.ylabel('Densit√©', fontsize=12)
plt.title('Distribution de la longueur des messages', fontsize=14)
plt.legend()

plt.subplot(1, 2, 2)
plt.boxplot([train_df['message_length'], test_df['message_length']], labels=['Train', 'Test'])
plt.ylabel('Longueur', fontsize=12)
plt.title('Boxplot longueur messages', fontsize=14)
plt.show()
```

#### Simuler un drift

```python
# Cr√©er des messages "production" avec des caract√©ristiques diff√©rentes
# Ex: Nouveau type de spam (crypto, COVID, etc.)

new_spam_messages = [
    "URGENT: Buy Bitcoin now! 1000% guaranteed returns! Limited time!",
    "COVID-19 vaccine available NOW! Click here for instant access!",
    "Get rich quick with NFTs! Join our exclusive group!",
]

# Pr√©dire
predictions = production_pipeline.predict(new_spam_messages)
probas = production_pipeline.predict_proba(new_spam_messages)

for msg, pred, proba in zip(new_spam_messages, predictions, probas):
    label = "SPAM" if pred == 1 else "HAM"
    conf = proba[pred]
    print(f"\n[{label}] (confiance: {conf:.2f})")
    print(f"{msg}")
```

üí° **En production** : Si de nombreux nouveaux messages ont des mots jamais vus √† l'entra√Ænement (ex: "NFT", "crypto"), le mod√®le peut moins bien performer ‚Üí n√©cessit√© de r√©-entra√Æner.

**Question 4.1** : Comment d√©tecteriez-vous automatiquement un drift en production ?

_R√©ponse_ :
- Monitorer la distribution des scores de pr√©diction
- Comparer les mots fr√©quents (nouveaux mots non vus)
- Tests statistiques (KS-test, PSI)
- Tracker les m√©triques business (taux de spam d√©tect√©)

---

### 4.4 Versioning et Reproductibilit√©

```python
from utils import save_model_info

metadata = {
    'model_version': 'v1.0',
    'f1_score': float(xgb_opt_f1),
    'roc_auc': float(xgb_opt_auc),
    'hyperparameters': {k: (int(v) if isinstance(v, (np.integer, np.int64)) else float(v) if isinstance(v, (np.floating, np.float64)) else v)
                        for k, v in random_search.best_params_.items()},
    'training_samples': int(len(messages_train)),
    'test_samples': int(len(messages_test)),
    'spam_ratio': float((y_train_raw == 1).sum() / len(y_train_raw)),
    'max_features': 3000,
    'ngram_range': '(1, 2)'
}

save_model_info(production_pipeline, 'model_info_v1.json', metadata=metadata)
print("‚úì M√©tadonn√©es sauvegard√©es")
```

**Livrable Partie 4** :
- ‚úÖ 2 runs track√©es dans MLflow
- ‚úÖ Pipeline de production cr√©√© et test√©
- ‚úÖ Analyse de drift effectu√©e
- ‚úÖ Mod√®le sauvegard√© avec m√©tadonn√©es

---

## üìä Livrables Finaux

√Ä rendre **√† la fin du TP** :

1. **Script Python compl√©t√©** : `tp5_votrenam.py`
   - Code propre et comment√©
   - R√©ponses aux questions de r√©flexion

2. **Pipeline sauvegard√©** : `spam_detector_pipeline.pkl`

3. **Rapport MLflow** : Export ou screenshots de vos runs

4. **README personnel** :
   - Meilleur mod√®le et ses performances
   - Top 10-20 mots les plus discriminants pour d√©tecter le spam
   - Difficult√©s rencontr√©es
   - Pistes d'am√©lioration

---

## üí° Conseils & Bonnes Pratiques

### Pour r√©ussir ce TP

- ‚úÖ **Fixez random_state=42** partout pour la reproductibilit√©
- ‚úÖ **TF-IDF : fit() sur train uniquement**, puis transform() sur test
- ‚úÖ **Utilisez les pipelines** pour √©viter le data leakage
- ‚úÖ **Privil√©giez F1-Score et ROC-AUC** plut√¥t que l'accuracy
- ‚úÖ **Analysez les mots importants** pour comprendre le mod√®le
- ‚úÖ **Commentez votre code** pour expliquer vos choix

### Pi√®ges √† √©viter

- ‚ùå Faire `fit()` du TfidfVectorizer sur le test set (DATA LEAKAGE!)
- ‚ùå Ne pas utiliser `class_weight='balanced'` ou `scale_pos_weight`
- ‚ùå Oublier la validation crois√©e stratifi√©e
- ‚ùå Se fier uniquement √† l'accuracy
- ‚ùå Ignorer l'interpr√©tabilit√© (quels mots d√©tectent le spam ?)

### Ressources utiles

- **Scikit-learn TF-IDF** : https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction
- **XGBoost** : https://xgboost.readthedocs.io/
- **LightGBM** : https://lightgbm.readthedocs.io/
- **MLflow** : https://mlflow.org/docs/latest/

---

## üéì Pour Aller Plus Loin (Bonus)

Si vous avez termin√© en avance, explorez ces pistes :

1. **Word2Vec ou BERT** : Embeddings plus avanc√©s que TF-IDF
2. **N-grams avanc√©s** : Tri-grams, character n-grams
3. **Nettoyage NLP** : Stemming, lemmatisation avec NLTK/spaCy
4. **SMOTE** : Sur-√©chantillonnage de la classe minoritaire
5. **Ensemble Methods** : Stacking de plusieurs mod√®les
6. **SHAP Values** : Interpr√©ter quels mots influencent chaque pr√©diction
7. **API REST** : D√©ployer avec Flask/FastAPI pour classifier des SMS en temps r√©el
8. **Analyse d'erreurs** : Examiner les faux positifs et faux n√©gatifs

---

## üìû Support

En cas de difficult√© :

1. Consultez les fonctions de `utils.py`
2. V√©rifiez la documentation officielle
3. Levez la main pour demander de l'aide
4. Collaborez avec vos voisins (sans copier-coller !)

---

**Bon courage et bon TP ! üöÄ**

_Le NLP est passionnant : vous allez voir comment l'IA "comprend" le texte !_
